{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f274f9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 0, 0, 0],\n",
      "        [4, 3, 5, 5, 0]])\n",
      "tensor([[7, 7, 1, 4, 0],\n",
      "        [3, 7, 5, 0, 0]])\n",
      "tensor([[[-1.0747,  0.7473, -0.4009, -0.1352,  0.2148, -0.3223, -0.2849,\n",
      "          -0.8968],\n",
      "         [-1.0747,  0.7473, -0.4009, -0.1352,  0.2148, -0.3223, -0.2849,\n",
      "          -0.8968],\n",
      "         [-0.1225,  0.0743,  0.3719, -0.0426,  0.3564, -1.2729,  0.1360,\n",
      "          -0.2235],\n",
      "         [ 0.9094, -0.9492,  0.3591,  0.6832, -0.7828,  0.1815,  1.1245,\n",
      "           0.4954],\n",
      "         [ 1.3248, -1.2998, -0.7829,  1.1595,  0.1091,  0.7341,  2.2985,\n",
      "          -0.2273]],\n",
      "\n",
      "        [[ 1.4708,  0.8553,  0.9317, -1.4997,  0.6191, -0.7203, -0.0137,\n",
      "           0.7326],\n",
      "         [-1.0747,  0.7473, -0.4009, -0.1352,  0.2148, -0.3223, -0.2849,\n",
      "          -0.8968],\n",
      "         [-0.4606, -0.9877, -1.7923, -1.5613, -1.3979,  0.5252,  2.4503,\n",
      "          -0.0534],\n",
      "         [ 1.3248, -1.2998, -0.7829,  1.1595,  0.1091,  0.7341,  2.2985,\n",
      "          -0.2273],\n",
      "         [ 1.3248, -1.2998, -0.7829,  1.1595,  0.1091,  0.7341,  2.2985,\n",
      "          -0.2273]]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([[   1.,   10.,  100., 1000.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# word embedding\n",
    "# 2 sentences\n",
    "batch_size = 2\n",
    "\n",
    "# size of word dictionary\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_dim = 8\n",
    "\n",
    "# max sequence length\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "max_position_len = 5\n",
    "\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
    "\n",
    "# padding\n",
    "src_seq_2_dim = [torch.unsqueeze(F.pad(torch.randint(1, 8, (L,)), (0, max_src_seq_len - L)), 0) for L in src_len]\n",
    "src_seq = torch.cat(src_seq_2_dim)\n",
    "\n",
    "tgt_seq_2_dim = [torch.unsqueeze(F.pad(torch.randint(1, 8, (L,)), (0, max_tgt_seq_len - L)), 0) for L in tgt_len]\n",
    "tgt_seq = torch.cat(tgt_seq_2_dim)\n",
    "print(src_seq)\n",
    "print(tgt_seq)\n",
    "\n",
    "# word embedding\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1, model_dim)\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1, model_dim)\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
    "print(tgt_embedding)\n",
    "\n",
    "# position embedding\n",
    "pos_mat = torch.arange(max_position_len).reshape((-1, 1))\n",
    "# from 0 to 8, each step is 2\n",
    "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1)) / model_dim)\n",
    "\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat / i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat / i_mat)\n",
    "\n",
    "print(pos_mat)\n",
    "print(i_mat)\n",
    "\n",
    "nn.Embedding(max_position_len, model_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87af44a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
